# Bayesian Optimization (BO)

A (actively updated) Paper List for Bayesian Optimization (BO).

******* *** *******

* Turner, R., Eriksson, D., McCourt, M., Kiili, J., Laaksonen, E., Xu, Z. and Guyon, I., 2021, August. [Bayesian optimization is superior to random search for machine learning hyperparameter tuning: Analysis of the black-box optimization challenge 2020](http://proceedings.mlr.press/v133/turner21a/turner21a.pdf). In NeurIPS Competition and Demonstration Track (pp. 3-26). PMLR. [ https://bbochallenge.com/ ]
* Cowen-Rivers, A.I., Lyu, W., Tutunov, R., Wang, Z., Grosnit, A., Griffiths, R.R., Maraval, A.M., Jianye, H., Wang, J., Peters, J. and Bou-Ammar, H., 2022. [HEBO: pushing the limits of sample-efficient hyper-parameter optimisation](https://www.jair.org/index.php/jair/article/view/13643). Journal of Artificial Intelligence Research, 74, pp.1269-1349.
* Kandasamy, K., Vysyaraju, K.R., Neiswanger, W., Paria, B., Collins, C.R., Schneider, J., Poczos, B. and Xing, E.P., 2020. [Tuning hyperparameters without grad students: Scalable and robust bayesian optimisation with dragonfly](). Journal of Machine Learning Research, 21(1), pp.3098-3124.
* Eriksson, D., Pearce, M., Gardner, J., Turner, R.D. and Poloczek, M., 2019. [Scalable global optimization via local bayesian optimization](https://proceedings.neurips.cc/paper/2019/hash/6c990b7aca7bc7058f5e98ea909e924b-Abstract.html). Advances in Neural Information Processing Systems.
* Snoek, J., Larochelle, H. and Adams, R.P., 2012. [Practical Bayesian optimization of machine learning algorithms](https://proceedings.neurips.cc/paper_files/paper/2012/hash/05311655a15b75fab86956663e1819cd-Abstract.html). Advances in Neural Information Processing Systems.

******* *** *******

* https://github.com/krasserm/bayesian-machine-learning
